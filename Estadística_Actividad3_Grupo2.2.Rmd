---
title: "Resolución Actividad 3 máster Bioinformática UNIR (2025)"
author: "Edurne García Vidal, Laura Yera Fernández, Sergio Gil Peña, Ander López Imas, Eva Coll Ripoll"
date: "2025-06-03"
output: 
  html_document:
    theme:
      bootswatch: flatly
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Estadística y R para Ciencias de la Salud: Actividad 3

## Librerias
```{r warning = FALSE, message = FALSE}
rm(list=ls())
library(stats)
library(ggplot2)
library(openxlsx)
library(tidyverse)
library(factoextra)
library(gtsummary)
library(car)
library(glmnet)
```

## Archivos
```{r}
data <- read.csv("Dataset expresión genes.csv", header = TRUE)
data <- data[, -1]
any(is.na(data)) # No hay ningún dato missing.

# Como el ID de los pacientes no corresponde al número de fila, vamos a añadir "ID_"
# a esa variable y usarla de rownames.
data$id <- paste0("ID_", data$id)
rownames(data) <- data$id

# Además, vamos a transformar la columna "extension (localizado / metastásico / regional)" 
# a una variable binaria "metastasis (si / no)" porque es la variable resultado que nos piden
# para el modelo de regresión logística que haremos posteriormente. Las observaciones con 
# "extension == metastasico" se han clasificado como "metastasis == si", el resto como "no".

data$metastasis <- ifelse (data$extension == "metastasico", "si", "no")
data$metastasis <- as.factor(data$metastasis)
```

## PCA y tablas
```{r}
# Realizaremos el PCA de los datos de expresión génica. Por ello, haremos una tabla
# incluyendo sólo esas variables (son las que empiezan por "AQ_").

data_genes <- data %>%
  select(starts_with("AQ_"))

# Miraremos cuantas variables tienen valores 0 en alguna de las observaciones
data_genes_zeros <- colSums(data_genes == 0)
data_genes_zeros

# Todas las variables tienen al menos un valor 0, pero a excepción de ADIPOQ y NOX5 son pocos.
# De todas maneras, no nos parecen suficientes como para eliminar ninguna variable.

# Haremos un boxplot para ver la expresión de los distintos genes
boxplot(data_genes)
# Hay valores tan elevados que distorsionan los boxplots, escalaremos los datos para que sean más comparables.

data_genes_scaled <- scale(data_genes)
boxplot(data_genes_scaled)

# Estos datos son los que usaremos para el PCA (podríamos escalarlos en la misma función de prcomp, pero
# como ya tenemos el dataframe escalado, usaremos este)

pca <- prcomp(data_genes_scaled)

# Con esto obtenemos una tabla con los 46 principal components, y el peso que 
# cada variable tiene en cada uno de estos PCs. Para poder sacar la varianza explicada
# de cada componente (o dimensión) usaremos las funciones de la libreria factoextra.

eigenvalues <- get_eigenvalue(pca)

# Para obtener la proporción de la varianza total acumulada, deberíamos usar la última
# columna de este nuevo dataframe.

Tabla_PCA_componentes <- as.data.frame(eigenvalues[, "cumulative.variance.percent"])
rownames(Tabla_PCA_componentes) <- rownames(eigenvalues) 
names(Tabla_PCA_componentes)[1] <- "Varianza_acumulada"
Tabla_PCA_componentes$Varianza_acumulada <- round(Tabla_PCA_componentes$Varianza_acumulada, 1)
Tabla_PCA_componentes
write.xlsx(Tabla_PCA_componentes, file = "Tabla_PCA_Componentes.xlsx", rowNames = TRUE)

# También se puede representar en un scree plot, aunque aquí representamos el 
# porcentaje de la variación explicada de cada componente/dimension (sin acumular)

fviz_eig(pca, addlabels = TRUE)

# Como podemos observar, si quisieramos escoger aquellos componentes o dimensiones 
# que juntos expliquen al menos un 70% de la varianza acumulada, deberíamos escoger hasta la Dim.5.

# Para hacer una tabla que nos muestre las cargas de cada variable en estas 5 dimensiones
# o componentes, podemos usar el componente "rotation" de la lista "pca". Cambiaremos
# los nombres de las filas para que coincidan con la Tabla_PCA_Componentes

Tabla_PCA_cargas <- as.data.frame(pca$rotation[, c("PC1", "PC2", "PC3", "PC4", "PC5")])
colnames(Tabla_PCA_cargas) <- c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")
Tabla_PCA_cargas <- Tabla_PCA_cargas %>%
  mutate(across(where(is.numeric), ~ round(., 2)))
Tabla_PCA_cargas
write.xlsx(Tabla_PCA_cargas, file = "Tabla_PCA_cargas.xlsx", rowNames = TRUE)
```

## Gráficos descriptivos de los componentes principales

### Gráficos para las variables
```{r}
# Aunque previamente habíamos dicho que necesitaríamos las primeras 5 dimensiones para explicar
# el 70% de la varianza explicada acumulada, ahora usaremos las dos primeras dimensiones para hacer
# los gráficos descriptivos, puesto que, por simplicidad visual y por la regla del codo,
# creemos que con dos dimensiones podría ser suficiente para representar la estructura principal de los datos.

# Primero extraeremos el valor de las variables, que se usarán a posteriori.

var <- get_pca_var(pca)

# Ahora haremos un gráfico de correlación variable para ver la relación entre
# todas las variables en las dimensiones 1 y 2. Además, aprovecharemos para colorear
# las variables según su valor de cos2, lo que nos indicará la importancia de cada variable.

correlacion_variable_graph <- fviz_pca_var(pca, col.var = "cos2", 
             gradient.cols = c("blue", "yellow", "red"),
             repel = TRUE) + 
  ggtitle("Gráfico de correlación variable del PCA") +
  theme(plot.title = element_text(hjust = 0.5))

correlacion_variable_graph 

# Tenemos tantas variables que el gráfico es un poco confuso, pero podemos ver
# que la mayoría de variables se van hacia la izquierda. Es decir, se relacionan
# negativamente con la Dim.1 (eje X). Esto lo podemos corroborar en la tabla de cargas,
# donde vemos que la mayoria son negativas en Dim.1.
# Además, segun los colores, podemos decir que la mayoría de las variables están bien representadas
# por estas dos dimensiones, a excepción de ADIPOQ, NOX5 (en azul) y SLC2A4 (en lila) que
# parecen no estar bien representadas en este plano y su varianza se podría explicar mejor en otras dimesiones. 
# Destacar que JAK1 (en rojo), en cambio, vemos que es una variable que está muy bien representada en este plano,
# y gran parte de su varianza está explicada por las dimesiones 1 y 2.

# La importancia de las variables para estas dimensiones también la podemos 
# representar en un gráfico de barras representando el valor de cos2

variable_cos2_graph <- fviz_cos2(pca, choice = "var", axes = 1:2) + 
  ggtitle("Importancia de las variables en Dim.1-2 (según Cos2)") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(size = 8))

variable_cos2_graph 

# Como intuíamos en la anterior gráfica, JAK1 es la variable más importante y en cambio ADIPOQ y NOX5 se ve
# claramente que en estas dimensiones tiene un peso muy bajo.

# Si ahora lo que queremos ver es la importancia de cada variable, pero por
# dimensión individual en vez de las dos primeras juntas, podemos hacer otro gráfico:

# Para la dimension 1

contribucion_dim1 <- fviz_contrib(pca, choice = "var", axes = 1) + 
  ggtitle("Importancia de las variables en la Dim.1") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(size = 8))

contribucion_dim1

# Para la dimension 2

contribucion_dim2 <- fviz_contrib(pca, choice = "var", axes = 2) + 
  ggtitle("Importancia de las variables en la Dim.2") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(size = 8))

contribucion_dim2

# Con esto podemos ver que, por ejemplo, JAK1 que la más importante en los gráficos
# anteriores, realmente es importante en la dimensión 1. No obstante, como la Dim.1
# ya contribuye a más del 50% de la varianza explicada, es normal que algo importante
# en esta dimensión lo siga siendo aunque tengamos en cuenta también la Dim.2.

# Lo que también observamos es que en la Dim.1 hay muchas variables que contribuyen de forma similar,
# mientras que en la Dim.2 el % de contribución de las variables baja rápidamente tras las primeras 6.
```

### Gráficos para las observaciones
```{r}
# Hasta ahora hemos estado viendo el impacto de las variables (genes) en los componentes
# del PCA, pero también podemos hacer gráficos similares para ver el impacto de las 
# observaciones (pacientes).

correlacion_individuals_graph <- fviz_pca_ind(pca, col.ind = "cos2",
             gradient.cols = c("blue", "yellow", "red"),
             repel = TRUE) + 
  ggtitle("Gráfico de correlación de los individuos del PCA") +
  theme(plot.title = element_text(hjust = 0.5))

correlacion_individuals_graph 

# En este gráfico vemos que los individuos están bastante repartidos, aunque sobre
# todo a lo largo del eje X (tiene sentido, ya que se trata de la Dim.1, que contribuye
# mucho más a la varianza explicada que la Dim.2). En cuanto a los colores, vemos que los
# valores más azules son los que están más cerca del origen, lo cual también tiene sentido
# porque significa que estas 2 dimensiones no tienen efecto en ellos. En cambio, si que vemos
# un grupo rojo a la derecha, en el que la dimension 1 afecta positivamente en ellos. Tal vez
# tendrán valores bajos de JAK1 (ya que la variable está negativamente relacionada con la Dim.1)
# y otras variables importantes para esa dimensión.

```

### Gráficos conjuntos variables - observaciones
```{r}
# Por último, también podemos hacer un biplot, que sería una combinación entre el gráfico
# de correlación de variables y el de individuos.


biplot_graph_dim1.2 <- fviz_pca_biplot(pca, 
                                col.ind = "blue",
                                col.var = "darkgreen",
                                axes = c(1, 2), 
                                repel = TRUE)  + 
  ggtitle("Gráfico biplot del PCA (Dimensiones 1 y 2)") +
  theme(plot.title = element_text(hjust = 0.5))

biplot_graph_dim1.2

# También podemos mirarlo para otras dimensiones

biplot_graph_dim1.3 <- fviz_pca_biplot(pca, 
                                col.ind = "blue",
                                col.var = "darkgreen",
                                axes = c(1, 3), 
                                repel = TRUE) + 
  ggtitle("Gráfico biplot del PCA (Dimensiones 1 y 3)") +
  theme(plot.title = element_text(hjust = 0.5))

biplot_graph_dim1.3

biplot_graph_dim2.3 <- fviz_pca_biplot(pca, 
                                col.ind = "blue",
                                col.var = "darkgreen",
                                axes = c(2, 3), 
                                repel = TRUE) + 
  ggtitle("Gráfico biplot del PCA (Dimensiones 2 y 3)") +
  theme(plot.title = element_text(hjust = 0.5))

biplot_graph_dim2.3

# En el plot de las Dim2. y Dim.3 vemos que hay muchos individuos cerca o en el 
# origen, porque ambas dimensiones contribuyen poco (5-6%) a la varianza. No obstante,
# seguimos viendo individuos alejados en los cuatro cuadrantes del gráfico, lo que
# significa que estas dimensiones siguen siendo importantes para separarlos.
# Aunque cueste ver, en este último gráfico también vemos variables (flechas) que
# apuntan en diferentes direcciones, no son casi todas negativas como ocurría en Dim.1,
# lo que también concuerda con los signos de las cargas de cada dimensión.
```

## Tabla descriptiva de los componentes principales
```{r}
# En primer lugar, debemos estudiar la distribución que presenta cada variables de nuestra tabla de genes
# para saber, si debemos usar media y desviación estándard o mediana y rango intercuartílico en las tablas
# descriptivas. 

# Con el comando apply haremos el test de shapiro por cada columna (gen) y sacaremos el p-valor.
# Importante, lo haremos en los datos SIN escalar.

data_genes_shapiro <- apply(data_genes, 2, function(x) shapiro.test(x)$p.value)
data_genes_shapiro

# Miramos cuantos genes tienen un p-value< 0.05 (significaria pues, que no siguen una distribución normal)

table(data_genes_shapiro < 0.05)

# Nos sale que 46 genes (de los 46 totales) tienen p<0.05. Es decir, los 46 genes siguen una distribución
# no normal. Por lo tanto, usaremos mediana y rango intercuartílico para las estadísticas descriptivas.


# Lo siguiente que vamos a hacer es dividir nuestra muestra, por cada componente
# o dimension, en terciles. Para eso, primero debemos sacar el valor de cada componente
# para cada paciente con el pca$x. Nos centraremos en los dos primeros componentes.

pca_values <- as.data.frame(pca$x)
pca_values <- pca_values[, c("PC1", "PC2")]

PC1_tercil <- quantile(pca_values$PC1, c(1/3, 2/3))
PC1_tercil

PC2_tercil <- quantile(pca_values$PC2, c(1/3, 2/3))
PC2_tercil

# Y ahora clasificaremos a los pacientes dependiendo de a qué tercil corresponden 
# en PC1 y PC2.

pca_values$PC1_tercil <- cut(pca_values$PC1,
                             breaks = c(-Inf, PC1_tercil, Inf),
                             labels = c("T1", "T2", "T3"),
                             right = FALSE)
pca_values$PC1_tercil <- factor(pca_values$PC1_tercil, levels = c("T1", "T2", "T3"))

pca_values$PC2_tercil <- cut(pca_values$PC2,
                             breaks = c(-Inf, PC2_tercil, Inf),
                             labels = c("T1", "T2", "T3"),
                             right = FALSE)
pca_values$PC2_tercil <- factor(pca_values$PC2_tercil, levels = c("T1", "T2", "T3"))

terciles <- data.frame(
  paciente = rownames(pca_values),
  PC1_tercil = pca_values$PC1_tercil,
  PC2_tercil = pca_values$PC2_tercil)


# Seguidamente, con la librería gtsummary haremos una tabla con las estadísticas descriptivas de cada
# gen en función de los pacientes incluidos en cada tercil de los componentes 1 y
# 2 del PCA.
# Además, para ver si hay diferencias entre los terciles de cada componente, realizaremos
# un test Kruskal-Wallis (ya que los datos no siguen distribución normal).

data_genes$PC1_tercil <- pca_values$PC1_tercil
data_genes$PC2_tercil <- pca_values$PC2_tercil

tabla_PC1 <- data_genes %>%
  select(1:47, PC1_tercil) %>%
  tbl_summary(by = PC1_tercil,
              statistic = all_continuous() ~ "{p50} ({p25} - {p75})",
              digits = all_continuous() ~ function(x) formatC(x, format = "e", digits = 2)) %>%
  add_p(test = all_continuous() ~ "kruskal.test",
        pvalue_fun = ~ style_pvalue(.x, digits = 3))

tabla_PC1

tabla_PC2 <- data_genes %>%
  select(c(1:48, PC2_tercil), -47) %>%
  tbl_summary(by = PC2_tercil,
              statistic = all_continuous() ~ "{p50} ({p25} - {p75})",
              digits = all_continuous() ~ function(x) formatC(x, format = "e", digits = 2)) %>%
  add_p(test = all_continuous() ~ "kruskal.test",
        pvalue_fun = ~ style_pvalue(.x, digits = 3))

tabla_PC2

# Para poder poner ambos PCs en la misma tabla con gtsummary, primero debemos crear una tabla para cada PCs por 
# separado, puesto que las variables pertenecen con más o menos peso a ambas componentes. Seguidamente, fusionaremos
# ambas tablas mediante tbl_merge que además nos permite poner títulos para indicar cada uno de los componentes
# principales, PC1 y PC2.

tabla_final <- tbl_merge(
  tbls = list(tabla_PC1, tabla_PC2),
  tab_spanner = c("**PC1**", "**PC2**")
) %>%
  modify_caption("**Estadísticos descriptivos de los genes de estudio.**")

tabla_final
```

## Modelo de regresión logística
```{r}
# Para la regresión logística usaremos de predictores los terciles de PC1 y PC2,
# que ya recogen información de la expresión de los 46 genes, por lo que crearemos
# una tabla que incluya las ID de los pacientes, los terciles, el resto de variables
# no-génicas y la variable respuesta metástasis (si / no)

data_regression <- data %>%
  select(-starts_with("AQ_")) %>%
  rename(paciente = id) %>%
  left_join(terciles, by = "paciente")

# Ahora vamos a asegurarnos que todas aquellas variables que no son numéricas se
# pasen a factor (menos la variable paciente)

data_regression_factors <- data_regression %>%
  mutate(
    across(.cols = where(is.character) & !all_of("paciente"), as.factor)
  )

# Nuestras variables predictoras serán los terciles de PC1 y PC2, pero debemos
# buscar variables confusoras que también deberían incluirse en el modelo de regresión.
# Las variables confusoras son aquellas que pueden estar asociadas a la variable 
# dependiente (metastasis) o a las predictoras (los terciles de PC1 y PC2),
# por lo que vamos a usar tests estadísticos para ver esas asociaciones.
# Quitaremos la variable extension porque es de donde se ha sacado metastasis (al inicio 
# del documento)

variables_factor <- data_regression_factors %>%
  select(-paciente, -metastasis, -PC1_tercil, -PC2_tercil, -extension) %>%
  select(where(is.factor))

# La primera vez que hicimos los tests, saltaron algunos avisos por que en algunas de
# las comparaciones el test de Chi cuadrado no es el mejor. En esos casos, debería hacerse
# un test de Fisher, así que hemos modificado el código para incluir esa opción con tryCatch.

chi_resultados <- lapply(names(variables_factor), function(x) {
  test <- tryCatch(
    chisq.test(data_regression_factors$metastasis, data_regression_factors[[x]]),
    warning = function(w) {
      fisher.test(data_regression_factors$metastasis, data_regression_factors[[x]])
    })
  data.frame(variable = x, p_value = test$p.value)
})

chi_resultados_df <- do.call(rbind, chi_resultados)

# Como hemos hecho muchas comparaciones, haremos una correccion del p-valor
chi_resultados_df$p_adjusted <- p.adjust(chi_resultados_df$p_value, method = "BH")
table(chi_resultados_df$p_value < 0.05)
table(chi_resultados_df$p_adjusted < 0.05)
# Ninguna de las variables categoricas está asociada a metástasis.

# Ahora haremos lo mismo pero para las variables no-categoricas. Como tenemos >30 observaciones
# asumiremos normalidad y directamente haremos el test de levene.
variables_numeric <- data_regression_factors %>%
  select(-paciente, -metastasis, -PC1_tercil, -PC2_tercil, -extension) %>%
  select(where(is.numeric))

numeric_resultados <- lapply(names(variables_numeric), function(x) {
  levene <- leveneTest(data_regression_factors[[x]] ~ data_regression_factors$metastasis)
  levene_pval <- levene$"Pr(>F)"[1]
  if (levene_pval > 0.05) {
    test <- t.test(data_regression_factors[[x]] ~ data_regression_factors$metastasis, var.equal = TRUE)
  } else {
    test <- t.test(data_regression_factors[[x]] ~ data_regression_factors$metastasis, var.equal = FALSE)
  }
  data.frame(variable = x, p_value = test$p.value)
})

numeric_resultados_df <- do.call(rbind, numeric_resultados)
numeric_resultados_df$p_adjusted <- p.adjust(numeric_resultados_df$p_value, method = "BH")
table(numeric_resultados_df$p_value < 0.05)
table(numeric_resultados_df$p_adjusted < 0.05)
# Ninguna de las variables numericas está asociada tampoco a metástasis.

# Ahora vamos a repetir lo mismo pero en vez de comparando a metástasis, comparando a las
# variables independientes (PC1_tercil y PC2_tercil)

chi_resultados_PC1_tercil <- lapply(names(variables_factor), function(x) {
  test <- tryCatch(
    chisq.test(data_regression_factors$PC1_tercil, data_regression_factors[[x]]),
    warning = function(w) {
      fisher.test(data_regression_factors$PC1_tercil, data_regression_factors[[x]])
    })
  data.frame(variable = x, p_value = test$p.value)
})

chi_resultados_PC1_tercil_df <- do.call(rbind, chi_resultados_PC1_tercil)
chi_resultados_PC1_tercil_df$p_adjusted <- p.adjust(chi_resultados_PC1_tercil_df$p_value, method = "BH")
table(chi_resultados_PC1_tercil_df$p_value < 0.05)
table(chi_resultados_PC1_tercil_df$p_adjusted < 0.05)
chi_resultados_PC1_tercil_df$variable[chi_resultados_PC1_tercil_df$p_value < 0.05]
# Aunque se pierda en el valor p ajustado, las variables vomitos y tumor están asociadas
# a PC1_tercil.

chi_resultados_PC2_tercil <- lapply(names(variables_factor), function(x) {
  test <- tryCatch(
    chisq.test(data_regression_factors$PC2_tercil, data_regression_factors[[x]]),
    warning = function(w) {
      fisher.test(data_regression_factors$PC2_tercil, data_regression_factors[[x]])
    })
  data.frame(variable = x, p_value = test$p.value)
})

chi_resultados_PC2_tercil_df <- do.call(rbind, chi_resultados_PC2_tercil)
chi_resultados_PC2_tercil_df$p_adjusted <- p.adjust(chi_resultados_PC2_tercil_df$p_value, method = "BH")
table(chi_resultados_PC2_tercil_df$p_value < 0.05)
table(chi_resultados_PC2_tercil_df$p_adjusted < 0.05)
chi_resultados_PC2_tercil_df$variable[chi_resultados_PC2_tercil_df$p_value < 0.05]
# En este caso, las asociadas a PC2_tercil (aunque en el p-valor sin ajustar) son
# las variables neuropatia y tumor.

numeric_resultados_PC1_tercil <- lapply(names(variables_numeric), function(x) {
  shapiro_pvals <- tapply(data_regression_factors[[x]], data_regression_factors$PC1_tercil, function(y) shapiro.test(y)$p.value)
  if(all(shapiro_pvals > 0.05)) {
    p_val <- summary(aov(data_regression_factors[[x]] ~ data_regression_factors$PC1_tercil))[[1]][["Pr(>F)"]][1]
  } else {
    p_val <- kruskal.test(data_regression_factors[[x]] ~ data_regression_factors$PC1_tercil)$p.value
  }
  data.frame(variable = x, p_value = p_val)
})

numeric_resultados_PC1_tercil_df <- do.call(rbind, numeric_resultados_PC1_tercil)
numeric_resultados_PC1_tercil_df$p_adjusted <- p.adjust(numeric_resultados_PC1_tercil_df$p_value, method = "BH")
table(numeric_resultados_PC1_tercil_df$p_value < 0.05)
table(numeric_resultados_PC1_tercil_df$p_adjusted < 0.05)
numeric_resultados_PC1_tercil_df$variable[numeric_resultados_PC1_tercil_df$p_value < 0.05]
numeric_resultados_PC1_tercil_df$variable[numeric_resultados_PC1_tercil_df$p_adjusted < 0.05]
# En este caso IgG y pcr presentan asociación a PC1_tercil por p-val, y linfocitos 
# tanto por p-val como por la ajustada.

numeric_resultados_PC2_tercil <- lapply(names(variables_numeric), function(x) {
  shapiro_pvals <- tapply(data_regression_factors[[x]], data_regression_factors$PC2_tercil, function(y) shapiro.test(y)$p.value)
  if(all(shapiro_pvals > 0.05)) {
    p_val <- summary(aov(data_regression_factors[[x]] ~ data_regression_factors$PC2_tercil))[[1]][["Pr(>F)"]][1]
  } else {
    p_val <- kruskal.test(data_regression_factors[[x]] ~ data_regression_factors$PC2_tercil)$p.value
  }
  data.frame(variable = x, p_value = p_val)
})

numeric_resultados_PC2_tercil_df <- do.call(rbind, numeric_resultados_PC2_tercil)
numeric_resultados_PC2_tercil_df$p_adjusted <- p.adjust(numeric_resultados_PC2_tercil_df$p_value, method = "BH")
table(numeric_resultados_PC2_tercil_df$p_value < 0.05)
table(numeric_resultados_PC2_tercil_df$p_adjusted < 0.05)
numeric_resultados_PC2_tercil_df$variable[numeric_resultados_PC2_tercil_df$p_value < 0.05]
# En este caso igE está asociada a PC2_tercil por el p-valor sin ajustar.


# En resumen, variables interesantes (posibles confusoras) que podriamos tener en cuenta 
# para el ajuste del modelo de regresión logística son:
# vomitos, tumor, neuropatia, igG, pcr, linfocitos e igE.

# Ahora probaremos diversos modelos de regresión incluyendo o no estas variables de ajuste.
# Pero primero vamos a asegurarnos de los niveles de las variables dependientes e independientes,
# para que la categoria de referencia sea la adecuada ("no" en metastasis).

modelo_sin_ajuste <- glm(metastasis ~ PC1_tercil + PC2_tercil, data = data_regression_factors, family = "binomial")
summary(modelo_sin_ajuste)
modelo_sin_ajuste_OR <- exp(cbind(OR = coef(modelo_sin_ajuste), confint(modelo_sin_ajuste)))
modelo_sin_ajuste_OR

# En cuanto a los p-valores del modelo, ninguno es < 0.05, por lo que ninguna de las variables
# parece tener un efecto en la variable dependiente. Cuando calculamos los OR, todos están cerca de 1,
# y los intervalos de confianza incluyen el 1, así que no parece que estén asociados a ningun riesgo.

modelo_todas_confusoras <- glm(metastasis ~ PC1_tercil + PC2_tercil + vomitos + tumor + neuropatia + igG + pcr + linfocitos + igE, data = data_regression_factors, family = "binomial")
summary(modelo_todas_confusoras)
modelo_todas_confusoras_OR <- exp(cbind(OR = coef(modelo_todas_confusoras), confint(modelo_todas_confusoras)))
modelo_todas_confusoras_OR

# Seguimos sin ver ninguna asociación estadísticamente significativa (los p-valores
# no son < 0.05, y en la tabla de OR todos los IC contienen 1). Además, vemos que
# AIC aumenta al añadir estas variables, por lo que la calidad de nuestro modelo
# ha empeorado.
comparacion_AIC <- data.frame(
  modelo = c("modelo_sin_ajuste", "modelo_todas_confusoras"),
  AIC = c(modelo_sin_ajuste$aic, modelo_todas_confusoras$aic)
)
comparacion_AIC
# Vamos a hacer la tabla de la regresión logística para el ejercicio usando el
# modelo_todas_confusoras (aunque sea peor), lo pondremos directamente en el 
# documento Word usando los datos de "summary(modelo_todas_confusoras)" y 
# "modelo_todas_confusoras_OR".
```

